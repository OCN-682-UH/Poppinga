---
title: "Week05 Notes"
author: "Haley Poppinga"
date: "2025-09-22"
output: github_document
---
Week 5b Lecture
Data wrangling: joins
2025-09-23

Outline of class
Quiz!
Review of tidyr
Independent Project update (It is on GitHub, Nyssa will go over next week)
Learning joins (part of the {dplyr} package)

left_join() -- with real data
Learn to make a tibble

Back to joins (with made up data as examples)

right_join()
inner_join()
full_join()
semi_join()
anti_join()
Homework

Practice with joins and dates in online assignment


Review
What function do you use to split up one column into multiple columns?


What function do you use to transition a wide data frame into a long data frame?



Intro to different types of join
Let's say you have multiple hierarchies of data and you want to join them into one big data set. Join functions are the way you would do it.


Data1
Site_number	Treatment	Nitrate	Temp
*1	High	1.2	7.2*
2	High	3.0	7.8
3	Low	2.4	8.0
4	Low	5.1	8.0
5	Low	1.1	7.9


Data2
Site_Number	Sample_number	Biomass
*1	1	12.2
1	2	14.0
1	3	11.9
1	4	10.0*

What we want
Site_Number	Sample_number	Biomass	Treatment	Nitrate	Temp
1	              1	          12.2	  High    	1.2	    7.2
1	              2	          14.0	  High	    1.2	    7.2
1	              3	          11.9  	High	    1.2	    7.2
1	              4	          10.0  	High	    1.2	    7.2
What is the column name that stayed consistent between Data1 and Data2 (i.e. what is the key/unique identifier here)?

Whenever you are collecting data make sure to include a unique ID for every sample. This will be extremely helpful when you need to connect multiple data sets together.

A more complicated example from your required reading




New dataset!
We are going to use a subset of data from Becker and Silbiger (2020) Journal of Experimental Biology.

In the data folder for this week in Fall-2025, you will see three .csv files:

1. site.characteristics.data.csv
2. Topt_data.csv
3. Data_dictionary.csv
Move both of them to the data folder of YOUR repo.

Explore the data dictionary to understand what you will be working with.

Basics: Danielle tested how nutrient loading and sedimentation affected thermal performance metrics of corals in Mo'orea, French Polynesia. She collected 10 corals from six sites with wide range in nutrients/sedimentation. Each coral underwent a heat ramping experiment to calculate thermal performance measures for respiration, photosynthesis, and calcification. She also measured several environmental characteristics at each site (nutrients, temperature, light, reef cover, sedimentation rate, etc.).



Set up your script for today

```{r}
### Today we are going to practice joins with data from Becker and Silbiger (2020) ####
### Created by: Haley Poppinga #############
### Created on: 2025-09-23 ####################

#### Load Libraries ######
library(tidyverse)
library(here)

### Load data ######
# Environmental data from each site
EnviroData<-read_csv(here("Week_05","data", "site.characteristics.data.csv"))

#Thermal performance data
TPCData<-read_csv(here("Week_05","data","Topt_data.csv"))
glimpse(EnviroData)
glimpse(TPCData)
# also use View()
```

Pivot the data
We notice that the TPCData is in wide format and the EnviroData is in long format. Let's convert the EnviroData to wide so that they are both in the same format
```{r}
EnviroData_wide <- EnviroData %>% 
  pivot_wider(names_from = parameter.measured,
              values_from = values)
View(EnviroData_wide)
```

Sort the data
Are you OCD like me? Does it bother you that the sites are not in order? If so, you can use the arrange() function to sort the dataframe by site.
```{r}
EnviroData_wide <- EnviroData %>% 
  pivot_wider(names_from = parameter.measured, # pivot the data wider
              values_from = values) %>%
  arrange(site.letter) # arrange the dataframe by site
View(EnviroData_wide)
```


left_join()
Let's say we want to look at the relationship between nutrient loading from the site and different thermal performance metrics. I can use left_join() to bring the two data frames together into one single data frame.


For left_join() to work you need a key that is identical in both dataframes (spelling, capitalization, everything). In this case, Danielle has site.letter present in both data frames. This is the variable that will be used to pair both datasets together.

In our case, there is no missing data. However, if there was an extra site in the right-hand data frame it would be excluded from the new dataset.
```{r}
FullData_left<- left_join(TPCData, EnviroData_wide)
## Joining with by = join_by(site.letter)
head(FullData_left)
```


relocate
Does it also bother you that the columns are not in a particular order? I like viewing all the character metadata on the left and all the collected numeric data on the right. Here is how to do it.
```{r}
FullData_left<- left_join(TPCData, EnviroData_wide) %>%
   relocate(where(is.numeric), .after = where(is.character)) # relocate all the numeric data after the character data
## Joining with by = join_by(site.letter)
head(FullData_left)
```


Think, pair, share
We now have our full data set. In your group, take your data set and calculate the mean and variance of all collected (TPC and environmental) data by site. (Hint: you can either use one of the summarise_at() functions or pivot the data longer to do this in less code)

So many joins
There are lots of different ways to join data together. To demonstrate, we will make up some datasets so that it is easier to highlight what is happening.

We will also learn:

right_join()
inner_join()
full_join()
semi_join()
anti_join()


Creating your own tibble
What is a tibble? It is a data frame, but simpler. It is what the tidyverse uses as a data frame.

To create a tibble we use tibble()
```{r}
# Make 1 tibble
T1 <- tibble(Site.ID = c("A", "B", "C", "D"), 
             Temperature = c(14.1, 16.7, 15.3, 12.8))
T1
```

```{r}
# make another tibble
T2 <-tibble(Site.ID = c("A", "B", "D", "E"), 
            pH = c(7.3, 7.8, 8.1, 7.9))
T2
```

left_join vs right_join
The only difference is which dataframe is being used as the base.

left_join(T1, T2) - joins to T1
right_join(T1, T2) - joins to T2

```{r}
left_join(T1, T2)
## Joining with by = join_by(Site.ID)
```

```{r}
right_join(T1, T2)
## Joining with by = join_by(Site.ID)
```
Notice where the missing value is for each data set


inner_join vs full_join
Inner join only keeps the data that is complete in both data sets.

inner_join vs full_join
Full join keeps everything.
```{r}
inner_join(T1, T2)
## Joining with by = join_by(Site.ID)
```

```{r}
full_join(T1, T2)
## Joining with by = join_by(Site.ID)
```

semi_join vs anti_join
semi_join keeps all rows from the first data set where there are matching values in the second data set, keeping just columns from the first data set.

Saves all rows in the first data set that do not match anything in the second data set. This can help you find possible missing data across datasets.

How would I find the extra data in y, in this example?


```{r}
semi_join(T1, T2)
## Joining with by = join_by(Site.ID)
```

```{r}
anti_join(T1, T2)
## Joining with by = join_by(Site.ID)
```


Today's totally awesome R package: {cowsay}
Have you every wanted an animal to talk to you? Well now you can.

install.packages("cowsay")
library(cowsay)

Homework

Practice joins on your own. You do not have to turn anything in for this lab, but there is for the online class.

Reminder: We are starting Quarto next week. If you have not yet completed the markdown lab from week 2, do it now. I will expect that you know the basics from that lab assignment before class on Tuesday.


____________________________________________________

Week 5b Lecture
Data wrangling: lubridate dates and times
2025-09-23


Learning about dates and times from the {lubridate} package

Converting and manipulating dates and times using {lubridate}
Homework

Practice with dates and times

You know what to do..... (Copy CondData.csv and DepthData.csv to your data folder)

```{r}
library(tidyverse)
library(here)
library(lubridate)
```

install.packages("lubridate") # package to deal with dates and times

What time is it now?
Even though this may seem silly if you have a clock, it is very helpful if you want to time stamp something in your code.

now() #what time is it now?
[1] "2025-09-16 14:31:26 HST"

You can also ask the time in other time zones.

now(tzone = "EST") # what time is it on the east coast
[1] "2025-09-16 19:31:26 EST"
now(tzone = "GMT") # what time in GMT
 [1] "2025-09-17 00:31:26 GMT"


If you only want the date and not the time

today()
[1] "2025-09-16"
today(tzone = "GMT")
 [1] "2025-09-17"

You can also ask if it is morning or night right now and if it is a leap year.

am(now()) # is it morning?
[1] FALSE
leap_year(now()) # is it a leap year?
[1] FALSE


Date specifications for lubridate
{lubridate} does a good job of guessing the format of your date if you give just a little hint.

First, your dates must be a character.

A common mistake is that you get an error trying to convert a date when it is a factor. Always check to make sure it is a character (i.e. put quotes around it).

Date	            function
2021-02-24	      ymd()
02/24/2021	      mdy()
February 24 2021	mdy()
24/02/2021	      dmy()

y = year
m = month
d = day

Date specifications for lubridate
These will all produce the same results as ISO dates

ymd("2021-02-24")
## [1] "2021-02-24"
mdy("02/24/2021")
## [1] "2021-02-24"
mdy("February 24 2021")
## [1] "2021-02-24"
dmy("24/02/2021")
## [1] "2021-02-24"



Date and Time specifications with lubridate
Time	function
2021-02-24 10:22:20 PM	ymd_hms()
02/24/2021 22:22:20	mdy_hms()
February 24 2021 10:22 PM	mdy_hm()
y = year
m = month (1st m)
d = day
h = hour
m = minute (2nd m)
s = second


Date and Time specifications with lubridate
ymd_hms("2021-02-24 10:22:20 PM")
## [1] "2021-02-24 22:22:20 UTC"
mdy_hms("02/24/2021 22:22:20")
## [1] "2021-02-24 22:22:20 UTC"
mdy_hm("February 24 2021 10:22 PM")
## [1] "2021-02-24 22:22:00 UTC"


Extracting specific date or time elements from datetimes
Let's make a vector of dates
```{r}
# make a character string
datetimes<-c("02/24/2021 22:22:20",
             "02/25/2021 11:21:10",
             "02/26/2021 8:01:52")
```

Let's make a vector of dates and covert them to datetimes.
```{r}
# make a character string
datetimes<-c("02/24/2021 22:22:20", 
             "02/25/2021 11:21:10", 
             "02/26/2021 8:01:52") 
# convert to datetimes
datetimes <- mdy_hms(datetimes)
```

Let's make a vector of dates and covert them to datetimes. Extract the months from the character string.
```{r}
# make a character string
datetimes<-c("02/24/2021 22:22:20", 
             "02/25/2021 11:21:10", 
             "02/26/2021 8:01:52") 
# convert to datetimes
datetimes <- mdy_hms(datetimes) 
month(datetimes)
## [1] 2 2 2
```

Let's make a vector of dates and covert them to datetimes. Extract the months from the character string. You can also save it as the month name.
```{r}
# make a character string
datetimes<-c("02/24/2021 22:22:20", 
             "02/25/2021 11:21:10", 
             "02/26/2021 8:01:52") 
# convert to datetimes
datetimes <- mdy_hms(datetimes) 
month(datetimes, label = TRUE)
## [1] Feb Feb Feb
## 12 Levels: Jan < Feb < Mar < Apr < May < Jun < Jul < Aug < Sep < ... < Dec
```

Let's make a vector of dates and covert them to datetimes. Extract the months from the character string. You can also save it as the month name.

```{r}
# make a character string
datetimes<-c("02/24/2021 22:22:20", 
             "02/25/2021 11:21:10", 
             "02/26/2021 8:01:52") 
# convert to datetimes
datetimes <- mdy_hms(datetimes) 
month(datetimes, label = TRUE, abbr = FALSE) #Spell it out
## [1] February February February
## 12 Levels: January < February < March < April < May < June < ... < December
```

Let's make a vector of dates and covert them to datetimes. Extract the days.
```{r}
# make a character string
datetimes<-c("02/24/2021 22:22:20", 
             "02/25/2021 11:21:10", 
             "02/26/2021 8:01:52") 
# convert to datetimes
datetimes <- mdy_hms(datetimes) 
month(datetimes, label = TRUE, abbr = FALSE) #Spell it out
day(datetimes) # extract day
## [1] 24 25 26
wday(datetimes, label = TRUE) # extract day of week
## [1] Wed Thu Fri
## Levels: Sun < Mon < Tue < Wed < Thu < Fri < Sat
```

Let's make a vector of dates and covert them to datetimes. Extract hour, minute, second.
```{r}
# make a character string
datetimes<-c("02/24/2021 22:22:20", 
             "02/25/2021 11:21:10", 
             "02/26/2021 8:01:52") 
# convert to datetimes
datetimes <- mdy_hms(datetimes) 
month(datetimes, label = TRUE, abbr = FALSE) #Spell it out 
day(datetimes) # extract day 
wday(datetimes, label = TRUE) # extract day of week
hour(datetimes)
minute(datetimes)
second(datetimes)
```

Adding dates and times
Let's say you are doing research in Mo'orea and one of your instruments is set to the correct timezone and the other one is not (not from my own experience or anything....).

Let's add 4 hours to all the datetimes



```{r}
datetimes + hours(4) # this adds 4 hours
## [1] "2021-02-25 02:22:20 UTC" "2021-02-25 15:21:10 UTC"
## [3] "2021-02-26 12:01:52 UTC"
```

Notice the s in hours

hour() extracts the hour component from a time and hours() is used to add hours to a datetime

Let's add 2 days to all the datetimes

```{r}
datetimes + hours(4) # this adds 4 hours
datetimes + days(2) # this adds 2 days
## [1] "2021-02-26 22:22:20 UTC" "2021-02-27 11:21:10 UTC"
## [3] "2021-02-28 08:01:52 UTC"
```

Notice the s in days

day() extracts the hour component from a time and days() is used to add hours to a datetime

You can do the same with minutes(), seconds(), months(), years(), etc.



Rounding dates
Round the dates to the nearest minute and nearest 5 minutes
```{r}
round_date(datetimes, "minute") # round to nearest minute
## [1] "2021-02-24 22:22:00 UTC" "2021-02-25 11:21:00 UTC"
## [3] "2021-02-26 08:02:00 UTC"
round_date(datetimes, "5 mins") # round to nearest 5 minute
## [1] "2021-02-24 22:20:00 UTC" "2021-02-25 11:20:00 UTC"
## [3] "2021-02-26 08:00:00 UTC"
```
You can do this with any set of times


Challenge - share in class Tuesday
Read in the conductivity data (CondData.csv) and convert the date column to a datetime. Use the %>% to keep everything clean.

This is temperature and salinity data taken at a site with groundwater while being dragged behind a float. Data were collected every 10 seconds. You will also notice depth data. That dataset will be used later during homework. Those data are taken from a pressure sensor, also collected data every 10 seconds.

Hint: Always look at your data in R after you read it in. Don't trust what the excel format looks like... There may be some seconds hiding, but excel only wants to show you the minutes. Also sometimes excel gets it right and says it's a date and other times it doesn't. Check to see if it's reading in as a character or date already or something totally different (in which case you need to make it a character in R)
```{r}

```


Today's totally awesome R package
Ever wanted to plot with cats? Now you can with {catterplots}!

library(devtools)
install_github("Gibbsdavidl/CatterPlots") # install the data
library(CatterPlots)
x <-c(1:10)# make up some data
y<-c(1:10)
catplot(xs=x, ys=y, cat=3, catcolor='blue')

```{r}

```

























