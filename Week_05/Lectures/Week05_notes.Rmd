---
title: "Week05 Notes"
author: "Haley Poppinga"
date: "2025-09-22"
output: github_document
---
### Week 5b Lecture  
#### Data wrangling: joins  
##### 2025-09-23


Outline of class. 
Quiz!  
Review of tidyr. 
Independent Project update (It is on GitHub, Nyssa will go over next week). 
Learning joins (part of the {dplyr} package). 

left_join() -- with real data
Learn to make a tibble

Back to joins (with made up data as examples)

* right_join() 
* inner_join()
* full_join()
* semi_join()
* anti_join()

Homework
Practice with joins and dates in online assignment


Review
1. What function do you use to split up one column into multiple columns?  
separate()

2. What function do you use to transition a wide data frame into a long data frame?  
pivot_longer() 
pivot_wider()


Intro to different types of join. 
Let's say you have multiple hierarchies of data and you want to join them into one big data set. Join functions are the way you would do it.


Data1

Site_number	Treatment	Nitrate	Temp
**1	High	1.2	7.2**
2	High	3.0	7.8
3	Low	2.4	8.0
4	Low	5.1	8.0
5	Low	1.1	7.9


Data2

Site_Number	Sample_number	Biomass
1	1	12.2
1	2	14.0
1	3	11.9
1	4	10.0
Site number 1 has 4 samples so...

What we want
Site_Number	Sample_number	Biomass	Treatment	Nitrate	Temp
1	              1	          12.2	  High    	1.2	    7.2
1	              2	          14.0	  High	    1.2	    7.2
1	              3	          11.9  	High	    1.2	    7.2
1	              4	          10.0  	High	    1.2	    7.2
What is the column name that stayed consistent between Data1 and Data2 (i.e. what is the key/unique identifier here)?
--> Site_Number


Whenever you are collecting data make sure to include a unique ID for every sample. 
* This will be extremely helpful when you need to connect multiple data sets together.

A more complicated example from your required reading




New dataset!
We are going to use a subset of data from Becker and Silbiger (2020) Journal of Experimental Biology.

In the data folder for this week in Fall-2025, you will see three .csv files:

1. site.characteristics.data.csv
2. Topt_data.csv
3. Data_dictionary.csv
Move both of them to the data folder of YOUR repo.

Explore the data dictionary to understand what you will be working with.

Basics: Danielle tested how nutrient loading and sedimentation affected thermal performance metrics of corals in Mo'orea, French Polynesia. She collected 10 corals from six sites with wide range in nutrients/sedimentation. Each coral underwent a heat ramping experiment to calculate thermal performance measures for respiration, photosynthesis, and calcification. She also measured several environmental characteristics at each site (nutrients, temperature, light, reef cover, sedimentation rate, etc.).



Set up your script for today

```{r}
### Today we are going to practice joins with data from Becker and Silbiger (2020) ####
### Created by: Haley Poppinga #############
### Created on: 2025-09-23 ####################

#### Load Libraries ######
library(tidyverse)
library(here)

### Load data ######
# Environmental data from each site
EnviroData<-read_csv(here("Week_05","data", "site.characteristics.data.csv"))

#Thermal performance data
TPCData<-read_csv(here("Week_05","data","Topt_data.csv"))
glimpse(EnviroData)
glimpse(TPCData)
# also use View()

#other ways to view
names(TPCData[,c(3:7)])
unique(EnviroData$parameter.measured)
```

Pivot the data
We notice that the TPCData is in wide format and the EnviroData is in long format. Let's convert the EnviroData to wide so that they are both in the same format
```{r}
EnviroData_wide <- EnviroData %>% 
  pivot_wider(names_from = parameter.measured,
              values_from = values)
#View(EnviroData_wide)
```

Sort the data
Are you OCD like me? Does it bother you that the sites are not in order? If so, you can use the arrange() function to sort the dataframe by site.
```{r}
EnviroData_wide <- EnviroData %>% 
  pivot_wider(names_from = parameter.measured, # pivot the data wider
              values_from = values) %>%
  arrange(site.letter) # arrange the dataframe by site
# View(EnviroData_wide)
```
usually you want your data to be wide but sometimes you have to pivot long

left_join()
Let's say we want to look at the relationship between nutrient loading from the site and different thermal performance metrics. I can use left_join() to bring the two data frames together into one single data frame.

* takes everything thats in the x and put it in the y
* left join is that girl
* join used most in data analysis and can be piped into tidyr/dplyr

For left_join() to work you need a key that is identical in both dataframes (spelling, capitalization, everything). In this case, Danielle has site.letter present in both data frames. This is the variable that will be used to pair both datasets together.

In our case, there is no missing data. However, if there was an extra site in the right-hand data frame it would be excluded from the new dataset.
```{r}
FullData_left<- left_join(TPCData, EnviroData_wide)
## Joining with by = join_by(site.letter)
head(FullData_left)

## Joining with by = join_by(site.letter)
# join_by this column is written the exact same way in both data frames
# = join_by is an argument
# can be helpful when you don't have the same names for data columns 

```


relocate
Does it also bother you that the columns are not in a particular order? I like viewing all the character metadata on the left and all the collected numeric data on the right. Here is how to do it.
```{r}
FullData_left<- left_join(TPCData, EnviroData_wide) %>%
   relocate(where(is.numeric), .after = where(is.character)) # relocate all the numeric data after the character data
## Joining with by = join_by(site.letter)
head(FullData_left)
```


Think, pair, share
We now have our full data set. In your group, take your data set and calculate the mean and variance of all collected (TPC and environmental) data by site. (Hint: you can either use one of the summarise_at() functions or pivot the data longer to do this in less code)
```{r}
# Think Pair Share
#  calculate the mean and variance of all collected (TPC and environmental) data by site. 
# (Hint: you can either use one of the summarise_at() functions or pivot the data longer to do this in less code)
FullData_left_long <- FullData_left %>% #rename it to an object
  drop_na() %>% # remove all NAs
  pivot_longer(c(E:substrate.cover),
               names_to = "Variables",
               values_to = "Values") %>%
  group_by(site.letter) %>% # group by site
  summarise(Param_means = mean(Values, na.rm = TRUE), # get mean 
            Param_vars = var(Values, na.rm = TRUE)) # get variance
# View(FullData_left_long)
```


So many joins
There are lots of different ways to join data together. To demonstrate, we will make up some datasets so that it is easier to highlight what is happening.

We will also learn:
* right_join()
* inner_join()
* full_join()
* semi_join()
* anti_join()


Creating your own tibble. 
What is a tibble? It is a data frame, but simpler. It is what the tidyverse uses as a data frame.

To create a tibble we use tibble()
```{r}
# Make 1 tibble
T1 <- tibble(Site.ID = c("A", "B", "C", "D"), 
             Temperature = c(14.1, 16.7, 15.3, 12.8))
T1
```

```{r}
# make another tibble
T2 <-tibble(Site.ID = c("A", "B", "D", "E"), 
            pH = c(7.3, 7.8, 8.1, 7.9))
T2
```

#### left_join vs right_join  
The only difference is which dataframe is being used as the base.

left_join(T1, T2) - joins to T1
right_join(T1, T2) - joins to T2

```{r}
left_join(T1, T2)
## Joining with by = join_by(Site.ID)
```

```{r}
right_join(T1, T2)
## Joining with by = join_by(Site.ID)
```
Notice where the missing value is for each data set

what is the difference?  
* the order of the columns
* and the order of the Site.ID

```{r}
left_join(T1, T2) #this one has ABCD
right_join(T1, T2) # this one has ABDE (get E because T2 is the data frame)
```

showing how they can be the same:
left_join(T1, T2) == 
  right_join(T2, T1) %>% arrange(Site.ID) %>% relocate(pH, .after = Temperature)



#### inner_join vs full_join
Inner join only keeps the data that is complete in both data sets.

what is the difference?  
order of the Site.ID and the order of the columns, but the data will be the same

inner_join vs full_join. 
Full join keeps everything.  
```{r}
inner_join(T1, T2)
## Joining with by = join_by(Site.ID)
```

```{r}
full_join(T1, T2)
## Joining with by = join_by(Site.ID)
```

Quiz:  
I have two dataframes (T1 and T2 - imaged below) with information on mouse lengths and mouse weights: If I run the following code, what should the new output look like? full_join(T1,T2)
full_join keeps everything
ABCD + ABDE --> ABCDE



#### semi_join vs anti_join  
semi_join keeps all rows from the first data set where there are matching values in the second data set, keeping just columns from the first data set.  

Saves all rows in the first data set that do not match anything in the second data set. This can help you find possible missing data across datasets.

How would I find the extra data in y, in this example?


```{r}
semi_join(T1, T2)
## Joining with by = join_by(Site.ID)
```

```{r}
anti_join(T1, T2)
## Joining with by = join_by(Site.ID)
```


Today's totally awesome R package: {cowsay}
Have you every wanted an animal to talk to you? Well now you can.

install.packages("cowsay")
library(cowsay)

Homework

Practice joins on your own. You do not have to turn anything in for this lab, but there is for the online class.

Reminder: We are starting Quarto next week. If you have not yet completed the markdown lab from week 2, do it now. I will expect that you know the basics from that lab assignment before class on Tuesday.


________________________________________________________________________


### Week 5b Lecture
#### Data wrangling: lubridate dates and times
##### 2025-09-23


Learning about dates and times from the {lubridate} package. 
* used for calculating dates and times and formatting them
* Converting and manipulating dates and times using {lubridate} package


Homework. 
* Practice with dates and times

You know what to do..... (Copy CondData.csv and DepthData.csv to your data folder)

```{r}
library(tidyverse)
library(here)
library(lubridate)
```

install.packages("lubridate") # package to deal with dates and times

What time is it now?  
* Even though this may seem silly if you have a clock, it is very helpful if you want to time stamp something in your code.

##### now() function
what time is it now?  
* used to stamp your code with something

[1] "2025-09-16 14:31:26 HST"


You can also ask the time in other time zones:
```{r}
now(tzone = "EST") # what time is it on the east coast
```
[1] "2025-09-16 19:31:26 EST"

```{r}
now(tzone = "GMT") # what time in GMT
```
[1] "2025-09-17 00:31:26 GMT"
* helpful if working in a lot of different time zones


If you only want the date and not the time:
today()
[1] "2025-09-16"


```{r}
today(tzone = "GMT")
```
 [1] "2025-09-17"

You can also ask if it is morning or night right now and if it is a leap year:
am(now()) 
asks the question; is it morning?
[1] FALSE
* will give you "TRUE" if it is morning time when you are setting up code
* useful for if you want to divide up some data into morning and afternoon or night
* setting up a plot that goes from midnight to morning 

```{r}
leap_year(now()) # is it a leap year?
```
[1] FALSE


##### Date specifications for lubridate:
* lubridate does a good job of guessing the format of your date if you give just a little hint.

First, your dates **must be a character**.
* cannot be a number or factor
* common mistake when you try to convert a date that's a factor --> gives you a bunch of NAs
* **turn into character by putting quotes around it**

* A common mistake is that you get an error trying to convert a date when it is a factor. Always check to make sure it is a character (i.e. put quotes around it).

Date	            function
2021-02-24	      ymd()       > year, month, day
02/24/2021	      mdy()       > month, day, year
February 24 2021	mdy()       > month, day, year
24/02/2021	      dmy()

y = year
m = month
d = day



Date specifications for lubridate
These will all produce the same results as ISO dates
```{r}
ymd("2021-02-24")
```
[1] "2021-02-24"
* true date for our analysis

```{r}
mdy("02/24/2021")
```
[1] "2021-02-24"
* converts into ISO date

```{r}
mdy("February 24 2021")
```
[1] "2021-02-24"


```{r}
dmy("24/02/2021")
```
[1] "2021-02-24"


Date **and** Time specifications with lubridate
Time	                      function
2021-02-24 10:22:20 PM	    ymd_hms()
02/24/2021 22:22:20	        mdy_hms()
February 24 2021 10:22 PM	  mdy_hm()

* add underscore for whether you also had hours, hours and minutes, etc.
* second m is minute
* going to assume you have military time unless you have AM or PM next to it
* excel may hide the fact that there's seconds, if you get a null error you probably have seconds in the data

y = year
m = month (1st m)
d = day
h = hour
m = minute (2nd m)
s = second



Date and Time specifications with lubridate:
```{r}
ymd_hms("2021-02-24 10:22:20 PM")
```
[1] "2021-02-24 22:22:20 UTC"


ymd_hm("2021-02-24 10:22:20 PM")
* gives you error because of seconds

```{r}
mdy_hms("02/24/2021 22:22:20")
```
[1] "2021-02-24 22:22:20 UTC"

```{r}
mdy_hm("February 24 2021 10:22 PM")
```
[1] "2021-02-24 22:22:00 UTC"


Quiz:  
I want to convert the following vector into dates. What function do I used? dates<-c("20-08-2021 10:50", " 21-08-2021 11:10", "22-08-2021 1:11")
dmy_hm(dates)





Extracting specific date or time elements from datetimes:
**Let's make a vector of dates**
* notice the quotes
* have to have same format within a vector
* need to have clean data 
* within Excel, dates need to be in the same format
```{r}
# make a character string
datetimes<-c("02/24/2021 22:22:20",
             "02/25/2021 11:21:10",
             "02/26/2021 8:01:52")
```

Let's make a vector of dates and **covert them to datetimes**.
```{r}
# make a character string
datetimes<-c("02/24/2021 22:22:20", 
             "02/25/2021 11:21:10", 
             "02/26/2021 8:01:52") 
# convert to datetimes
datetimes <- mdy_hms(datetimes) # month, day, year, hours, minutes, seconds ISO format
```


Let's make a vector of dates and covert them to datetimes. **Extract the months from the character string**.
```{r}
# make a character string
datetimes<-c("02/24/2021 22:22:20", 
             "02/25/2021 11:21:10", 
             "02/26/2021 8:01:52") 
# convert to datetimes
datetimes <- mdy_hms(datetimes) 
month(datetimes) # which month were each of these rows from
## [1] 2 2 2
```
* helpful when you took the average by month
* take month function, mutate dataframe so you have a column of months


Let's make a vector of dates and covert them to datetimes. Extract the months from the character string. **You can also save it as the month name.**
```{r}
# make a character string
datetimes<-c("02/24/2021 22:22:20", 
             "02/25/2021 11:21:10", 
             "02/26/2021 8:01:52") 
# convert to datetimes
datetimes <- mdy_hms(datetimes) 
month(datetimes, label = TRUE) # names of the month instead of 2
## [1] Feb Feb Feb
## 12 Levels: Jan < Feb < Mar < Apr < May < Jun < Jul < Aug < Sep < ... < Dec
# now a factor, helps you plot where it doesnt put it alphabetical order but the right order of months
```

Let's make a vector of dates and covert them to datetimes. Extract the months from the character string. You can also save it as the month name. **Don't want it to be abbreviated**
```{r}
# make a character string
datetimes<-c("02/24/2021 22:22:20", 
             "02/25/2021 11:21:10", 
             "02/26/2021 8:01:52") 
# convert to datetimes
datetimes <- mdy_hms(datetimes) 
month(datetimes, label = TRUE, abbr = FALSE) #Spell it out, not abbreviated
## [1] February February February
## 12 Levels: January < February < March < April < May < June < ... < December
```


Let's make a vector of dates and covert them to datetimes. *Extract the days* and weekday.
```{r}
# make a character string
datetimes<-c("02/24/2021 22:22:20", 
             "02/25/2021 11:21:10", 
             "02/26/2021 8:01:52") 
# convert to datetimes
datetimes <- mdy_hms(datetimes) 
month(datetimes, label = TRUE, abbr = FALSE) #Spell it out
day(datetimes) # extract day, get average by day
## [1] 24 25 26
wday(datetimes, label = TRUE) # extract day of week
## [1] Wed Thu Fri
## Levels: Sun < Mon < Tue < Wed < Thu < Fri < Sat
```

Let's make a vector of dates and covert them to datetimes. *Extract hour, minute, second*.
```{r}
# make a character string
datetimes<-c("02/24/2021 22:22:20", 
             "02/25/2021 11:21:10", 
             "02/26/2021 8:01:52") 
# convert to datetimes
datetimes <- mdy_hms(datetimes) 
month(datetimes, label = TRUE, abbr = FALSE) #Spell it out 
day(datetimes) # extract day 
wday(datetimes, label = TRUE) # extract day of week
hour(datetimes) # extract the hours, take an average by hours
minute(datetimes) # extract the minutes
second(datetimes) #extract the seconds
```

Quiz:  
If I use the "dates" vector from above and extract the day from each date, what function do I use?
day(dates)






Adding dates and times
* Let's say you are doing research in Mo'orea and one of your instruments is set to the correct timezone and the other one is not (not from my own experience or anything....).

Let's add 4 hours to all the datetimes:
```{r}
datetimes + hours(4) # this adds 4 hours
## [1] "2021-02-25 02:22:20 UTC" "2021-02-25 15:21:10 UTC"
## [3] "2021-02-26 12:01:52 UTC"
```
* add however many hours the dataset was off
* Notice the s in hours
  * previously used hour() function to remove the hours, want to know hours
  * now want to add hours to datetime, so use hour to add to every single character in vector

* hour() extracts the hour component from a time and hours() is used to add hours to a datetime


Let's add 2 days to all the datetimes:
```{r}
datetimes + hours(4) # this adds 4 hours
datetimes + days(2) # this adds 2 days
## [1] "2021-02-26 22:22:20 UTC" "2021-02-27 11:21:10 UTC"
## [3] "2021-02-28 08:01:52 UTC"
```

* Notice the s in days

* day() extracts the hour component from a time and days() is used to add hours to a datetime

You can do the same with minutes(), seconds(), months(), years(), etc.
* helpful for temperature data and conductivity data that isnt aligned when you set the time, so you can align it


Rounding dates
* Round the dates to the nearest minute and nearest 5 minutes
```{r}
round_date(datetimes, "minute") # round to nearest minute
## [1] "2021-02-24 22:22:00 UTC" "2021-02-25 11:21:00 UTC"
## [3] "2021-02-26 08:02:00 UTC"
# both sensors started differently, so you can bring them together by rounding to nearest minute

round_date(datetimes, "5 mins") # round to nearest 5 minute
## [1] "2021-02-24 22:20:00 UTC" "2021-02-25 11:20:00 UTC"
## [3] "2021-02-26 08:00:00 UTC"
# maybe doing some smothing function where you want to round to nearest 5 minutes
```
* You can do this with any set of times



Challenge - share in class Tuesday
Read in the conductivity data (CondData.csv) and convert the date column to a datetime. 
Use the %>% to keep everything clean.

This is temperature and salinity data taken at a site with groundwater while being dragged behind a float. 
Data were collected every 10 seconds. 
You will also notice depth data. That dataset will be used later during homework. 
Those data are taken from a pressure sensor, also collected data every 10 seconds.

Hint: Always look at your data in R after you read it in. Don't trust what the excel format looks like... There may be some seconds hiding, but excel only wants to show you the minutes. 
Also sometimes excel gets it right and says it's a date and other times it doesn't. 
Check to see if it's reading in as a character or date already or something totally different (in which case you need to make it a character in R)

Note:
* can pipe into lubridate functions
* if changing a column, still have to use mutate regardless of whatever function you are using
   * still have to pipe to mutate and then use the month function to create a new column of month
* always want to look at your data in R first because Excel can be bad
    * sometimes it shows you only hour and minutes and seconds its hiding
    * sometimes it thinks its a date or a character, if its a character you have to convert it

```{r}
CondData<-read_csv(here("Week_05","data","CondData.csv"))
glimpse(CondData) # there are seconds

CondData_clean<-CondData %>%
  drop_na() %>% #filters out everything that is not a complete row
  mutate(datetimes = mdy_hms(date)) %>% # convert date column to year, month, day, hour, minute, second
  mutate(month = month(datetimes, label = TRUE, abbr = FALSE)) # month column with full month labels
glimpse(CondData_clean)
```


Today's totally awesome R package
Ever wanted to plot with cats? Now you can with {catterplots}!

library(devtools)
install_github("Gibbsdavidl/CatterPlots") # install the data (doesnt work)
library(CatterPlots)
x <-c(1:10)# make up some data
y<-c(1:10)
catplot(xs=x, ys=y, cat=3, catcolor='blue')


library(devtools)
library(CatterPlots) # not working

























